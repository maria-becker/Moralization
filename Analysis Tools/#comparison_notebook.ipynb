{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Moralizations with other Texts\n",
    "\n",
    "This notebook demonstrates how the modules of this directory can be used to compare linguistic features of moralizations with non-moralizing texts, such as thematizations of morality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell needs to be executed only if the notebook is run in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code should be run in Google Colab only.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if the code is running in Google Colab\n",
    "if 'google.colab' in str(get_ipython()) and 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !git clone https://github.com/maria-becker/Moralization/\n",
    "    %cd \"/content/Moralization/Annotation Analysis Tools/data_analysis\"\n",
    "else:\n",
    "    print(\"This code should be run in Google Colab only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These modules always need to be imported; always execute the cell below.\n",
    "Note that these imports (and the imports inside the imported modules) only work with Unix/Linux-style filepaths. Under Windows, *corpus_extraction* and *xmi_analysis_util* have to be imported with other means (such as copying them into the current directory or installing them with pip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pytz/__init__.py:31: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  match = re.match(\"^#\\s*version\\s*([0-9a-z]*)\\s*$\", line)\n"
     ]
    }
   ],
   "source": [
    "from analysis_functions import (\n",
    "    moral_vs_nonmoral,\n",
    "    surface_corpus,\n",
    "    _util_ as util,\n",
    "    _corpus_extraction_ as corpus_extraction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a List of Items to Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways of creating lists of items whose frequencies we want to compare. The first is just to do it manually, like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_list = [\n",
    "    \"würde\",\n",
    "    \"recht\",\n",
    "    \"gerechtigkeit\",\n",
    "    \"demokratie\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way is to use data from the corpora.\n",
    "The module *comparison_list_gen* makes it possible to create dictionaries of lemmata or tokens that appear inside different types of annotations, where the keys are the tokens/lemmata and the values are the number of appearances.\n",
    "Subsequently, these dictionaries can be used for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError: {'Coordinates': (43846, 43875), 'Category': 'Subversion'} -- Is the label inside a moralization?\n"
     ]
    }
   ],
   "source": [
    "moral_filepath = \"/home/brunobrocai/Desktop/Code/moralization/Testfiles/test_gerichtsurteile_DE.xmi\"\n",
    "corpus = corpus_extraction.Corpus(moral_filepath)\n",
    "\n",
    "# Other functions that could be used here:\n",
    "# tokens_in_annotations() for tokens\n",
    "# pos_lemmata_in_annotations() for lemmata with specific POSs\n",
    "\n",
    "comparison_lemmata = surface_corpus.lemmata_in_annotation(\n",
    "    category=\"all_morals\",\n",
    "    language=\"de\",\n",
    "    corpus=corpus,\n",
    "    tagger=\"HanTa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the dictionary to get an overview of common lemmata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt 1\n",
      "Beschäftigte 1\n",
      "eugenisch 1\n",
      "Freiheit 1\n",
      "körperlich 1\n",
      "Unversehrtheit 1\n",
      "ungerechtfertigt 1\n",
      "Einschränkung 1\n",
      "Meinung 1\n",
      "Pressefreiheit 1\n",
      "national 1\n",
      "Sicherheit 1\n",
      "unmittelbar 1\n",
      "entsprechend 1\n",
      "Kriminalität 1\n",
      "“ 1\n",
      "kalkulieren 1\n",
      "Rechtsverstoß 1\n",
      "Regenbogenpresse 1\n",
      "rechtswidrig 1\n",
      "Ostdeutschland 1\n",
      "Ziel 1\n",
      "Rechtssicherheit 1\n",
      "grundgesetzlich 1\n",
      "garantiert 1\n",
      "Gefahr 1\n",
      "Allgemeinheit 1\n",
      "Rechtsstaatlichkeit 1\n",
      "Arbeitslosigkeit 1\n",
      "Berufsleben 1\n",
      "Bevormundung 1\n",
      "extrem 1\n",
      "Angriff 1\n",
      "auf 1\n",
      "Super-gau 1\n",
      "dramatisch 1\n",
      "eklatant 1\n",
      "unzulässig 1\n",
      "Elternrecht 1\n",
      "einen 1\n",
      "Justiz 1\n",
      "zu 1\n",
      "Zweck 1\n",
      "dieser 1\n",
      "kalt 1\n",
      "Krieg 1\n",
      "wegen 1\n",
      "sein 1\n",
      "sexuell 1\n",
      "Ausrichtung 1\n",
      "Mutter 1\n",
      "Familie 1\n",
      "Staatsfreiheit 1\n",
      "Rundfunk 1\n",
      "Interesse 1\n",
      "Meinungsvielfalt 1\n",
      "jed 1\n",
      "Gängelung 1\n",
      "Medium 1\n",
      "durch 1\n",
      "Staat 1\n",
      "Instrumentalisierung 1\n",
      "Teilnahme 1\n",
      "an 1\n",
      "gesellschaftlich 1\n",
      "Ausgrenzung 1\n",
      "Sozialstaatsprinzip 1\n",
      "'' 1\n",
      "Altersarmut 1\n",
      "Leben 2\n",
      "” 2\n",
      "Schutz 2\n",
      "verstärkt 2\n",
      "Schwarzhandel 2\n",
      "islamisch 2\n",
      "Extremismus 2\n",
      "unangemessen 2\n",
      "Benachteiligung 2\n",
      "Menschenwürde 2\n",
      "Demokratie 2\n",
      "Presse 2\n",
      "Informationsfreiheit 2\n",
      "beispiellos 2\n",
      "politisch 2\n",
      "Meinungsfreiheit 2\n",
      "von 3\n",
      "für 3\n",
      "Eingriff 3\n",
      "mißbrauchen 4\n",
      "Selbstbestimmungsrecht 4\n",
      "Diskriminierung 5\n",
      "in 5\n",
      "und 6\n",
      "benachteiligen 9\n",
      "„ 9\n",
      "ein 10\n",
      "der 31\n",
      "# 34\n"
     ]
    }
   ],
   "source": [
    "for lemma, count in comparison_lemmata.items():\n",
    "    print(lemma, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use list comprehension to get a list of lemmata whose frequencies we can compare. In this example, we are taking all lemata with an absolute frequency of more than 10, them printing it to make sure it contains only interesting lemmata (and then remove those we do not care for)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['der']\n"
     ]
    }
   ],
   "source": [
    "comparison_list = [l for l in comparison_lemmata if comparison_lemmata[l] > 10]\n",
    "comparison_list.remove(\"#\")\n",
    "print(comparison_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Corpora to Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to create two more lists of strings. These should contain lists of moralizations and a type of non-moralizing texts. They will be the basis on which the frequencies of phenomena such as tokens or lemmata will be compared.\n",
    "\n",
    "This can be achieved via the *comparison_corpus_gen* module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a list of non-moralizing strings by using excel files that contain categorizations, where a 3 in the second column is assigned to moralizations and 0-2 are assigned to non-moralizing speech.\n",
    "\n",
    "In the following code, we retrieve text tagged with a 0 -- in other words, thematizations of morality (see annotation guidelines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klägerin war eine 55-jährige Arbeitslose, die mit ihrem Mann in \"Bedarfsgemeinschaft\" zusammenlebt.\n",
      "Deswegen bekommen beide pro Kopf nur 311 Euro ALG II statt des vollen Satzes von 354 Euro.\n",
      "Es reiche aber für eine menschenwürdige \"bescheidene Lebensführung\" noch aus.\n"
     ]
    }
   ],
   "source": [
    "nonmoral_list = surface_corpus.list_nonmoral_strings_from_corpus(\n",
    "    corpus\n",
    ")\n",
    "for element in nonmoral_list[:3]:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonmoral_list2 = surface_corpus.list_nonmoral_strings_from_xlsx(\n",
    "    \"/home/brunobrocai/Data/Moralization/Excels/Alle_bearbeiteten_Annotationen_positiv_final.xlsx\",\n",
    "    [\"Gerichtsurteile\"],\n",
    "    [0, 1, 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve moralizing strings via xmi files. (While it is possible to use the above function to retrieve items tagged with a 3, these annotations are of lower quality than those in the xmi files.) The function call below is rather self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Bundesgerichtshof (BGH) entschied vergangene Woche in Karlsruhe, dass solche Abgeltungsklauseln den Mieter \"unangemessen\" #benachteiligen,# hieß es\n",
      "----------\n",
      "Die Luxemburger Richter entschieden nun, dass eine unmittelbare Diskriminierung gegeben sei, falls sich überlebende Ehegatten und überlebende Lebenspartner in Bezug auf die Versorgung in einer vergleichbaren Lage befinden\n",
      "----------\n",
      "Die Behörden seien verpflichtet, einen Zuschuss und nicht nur ein Darlehen zum Arbeitslosengeld II zu gewähren. ### \"Kinder sollen gerade im schulischen Bereich nicht #benachteiligt# werden\", hieß es in der Urteilsbegründung. ###\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "moral_list = surface_corpus.list_moralization_strings_from_corpus(\n",
    "    corpus,\n",
    ")\n",
    "for element in moral_list[:3]:\n",
    "    print(element)\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the three lists of strings we generated - the lemmata whose frequencies will be compared, and the lists of moralizing and non-moralizing speech on which we are basing our analysis, to see whether the lemmata are significantly more frequent in moralizations and hence indicative of that speech act."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "der {'likelihood_moral': 0.0351931330472103, 'likelihood_nonmoral': 0.02328589909443726, 'ratio': 1.5113495469718645, 'diff_coeficient': 0.2036154415813759, 'pvalue_fisher': 0.04147464766474819, 'contingency_table': [[41, 1124], [72, 3020]]}\n"
     ]
    }
   ],
   "source": [
    "comparison_dict = moral_vs_nonmoral.compare_token_likelihood_dict(\n",
    "    moral_list=moral_list,\n",
    "    nonmoral_list=nonmoral_list,\n",
    "    token_list=comparison_list,\n",
    "    language='german'\n",
    ")\n",
    "for lemma, stats in comparison_dict.items():\n",
    "    print(lemma, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write the results into an excel file, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvn.dict_to_xlsx(comparison_dict, \"output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
