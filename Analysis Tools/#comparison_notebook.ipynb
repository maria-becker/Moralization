{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Moralizations with other Texts\n",
    "\n",
    "This notebook demonstrates how the modules of this directory can be used to compare linguistic features of moralizations with non-moralizing texts, such as thematizations of morality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell needs to be executed only if the notebook is run in Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the code is running in Google Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !git clone https://github.com/maria-becker/Moralization/\n",
    "    %cd \"/content/Moralization/Annotation Analysis Tools/data_analysis\"\n",
    "else:\n",
    "    print(\"This code should be run in Google Colab only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These modules always need to be imported; always execute the cell below.\n",
    "Note that these imports (and the imports inside the imported modules) only work with Unix/Linux-style filepaths. Under Windows, *corpus_extraction* and *xmi_analysis_util* have to be imported with other means (such as copying them into the current directory or installing them with pip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_functions import (\n",
    "    moral_vs_nonmoral,\n",
    "    surface_corpus,\n",
    "    _util_ as util,\n",
    "    _corpus_extraction_ as corpus_extraction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a List of Items to Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways of creating lists of items whose frequencies we want to compare. The first is just to do it manually, like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_list = [\n",
    "    \"wÃ¼rde\",\n",
    "    \"recht\",\n",
    "    \"gerechtigkeit\",\n",
    "    \"demokratie\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way is to use data from the corpora.\n",
    "The module *comparison_list_gen* makes it possible to create dictionaries of lemmata or tokens that appear inside different types of annotations, where the keys are the tokens/lemmata and the values are the number of appearances.\n",
    "Subsequently, these dictionaries can be used for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_filepath = \"/home/brunobrocai/Desktop/Code/moralization/Testfiles/test_gerichtsurteile_DE.xmi\"\n",
    "corpus = corpus_extraction.Corpus(moral_filepath)\n",
    "\n",
    "# Other functions that could be used here:\n",
    "# tokens_in_annotations() for tokens\n",
    "# pos_lemmata_in_annotations() for lemmata with specific POSs\n",
    "\n",
    "comparison_lemmata = surface_corpus.lemmata_in_annotation(\n",
    "    category=\"all_morals\",\n",
    "    language=\"de\",\n",
    "    corpus=corpus,\n",
    "    tagger=\"HanTa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the dictionary to get an overview of common lemmata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lemma, count in comparison_lemmata.items():\n",
    "    print(lemma, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use list comprehension to get a list of lemmata whose frequencies we can compare. In this example, we are taking all lemata with an absolute frequency of more than 10, them printing it to make sure it contains only interesting lemmata (and then remove those we do not care for)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_list = [l for l in comparison_lemmata if comparison_lemmata[l] > 10]\n",
    "comparison_list.remove(\"#\")\n",
    "print(comparison_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Corpora to Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to create two more lists of strings. These should contain lists of moralizations and a type of non-moralizing texts. They will be the basis on which the frequencies of phenomena such as tokens or lemmata will be compared.\n",
    "\n",
    "This can be achieved via the *comparison_corpus_gen* module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a list of non-moralizing strings by using excel files that contain categorizations, where a 3 in the second column is assigned to moralizations and 0-2 are assigned to non-moralizing speech.\n",
    "\n",
    "In the following code, we retrieve text tagged with a 0 -- in other words, thematizations of morality (see annotation guidelines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonmoral_list = surface_corpus.list_nonmoral_strings_from_corpus(\n",
    "    corpus\n",
    ")\n",
    "for element in nonmoral_list[:3]:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonmoral_list2 = surface_corpus.list_nonmoral_strings_from_xlsx(\n",
    "    \"/home/brunobrocai/Data/Moralization/Excels/Alle_bearbeiteten_Annotationen_positiv_final.xlsx\",\n",
    "    [\"Gerichtsurteile\"],\n",
    "    [0, 1, 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrieve moralizing strings via xmi files. (While it is possible to use the above function to retrieve items tagged with a 3, these annotations are of lower quality than those in the xmi files.) The function call below is rather self-explanatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_list = surface_corpus.list_moralization_strings_from_corpus(\n",
    "    corpus,\n",
    ")\n",
    "for element in moral_list[:3]:\n",
    "    print(element)\n",
    "    print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the three lists of strings we generated - the lemmata whose frequencies will be compared, and the lists of moralizing and non-moralizing speech on which we are basing our analysis, to see whether the lemmata are significantly more frequent in moralizations and hence indicative of that speech act."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_dict = moral_vs_nonmoral.compare_token_likelihood_dict(\n",
    "    moral_list=moral_list,\n",
    "    nonmoral_list=nonmoral_list,\n",
    "    token_list=comparison_list,\n",
    "    language='german'\n",
    ")\n",
    "for lemma, stats in comparison_dict.items():\n",
    "    print(lemma, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write the results into an excel file, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvn.dict_to_xlsx(comparison_dict, \"output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
