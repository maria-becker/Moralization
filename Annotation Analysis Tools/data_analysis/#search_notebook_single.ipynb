{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instanzen-Suche\n",
    "Mit diesem Notebook können alle Instanzen aufgelistet werden, die bestimmte Bedingungen erfüllen. Die Bedingungen können frei gewählt werden. Sie bestehen aus einer Annotationskategorie und einer weiteren Bedingung. Folgende Suchparameter gibt es:\n",
    "+ nach Wörtern (Lexemen)\n",
    "+ Nach Wortarten oder Wortartenlisten (benutzt wird das [Stuttgart-Tübingen-Tagset](https://homepage.ruhr-uni-bochum.de/stephen.berman/Korpuslinguistik/Tagsets-STTS.html))\n",
    "+ Nach Anzahl vergebener Kategorietags (z.B.: 3 Moralwerte)\n",
    "+ Nach bestimmten Annotationslabels (z.B.: Forderer)\n",
    "\n",
    "Bezüglich der Annotationskategorien stehen Folgende zur Verfügung:\n",
    "+ *obj_morals*: Alle Moralwerte, die keine subjektiven Ausdrücke sind\n",
    "+ *subj_morals*: Moralwerte, die subjektive Ausdrücke sind\n",
    "+ *all_morals*: Alle Moralwerte\n",
    "+ *protagonists*: Alle Protagonisten-Token\n",
    "+ *protagonists_doubles*: Alle Protagonisten-Rollen (Achtung: manche Protagonisten-Token werden dabei doppelt gezählt - nämlich, wenn sie mehrere Rollen haben)\n",
    "+ *com_functions*: Kommunikative Funktionen\n",
    "+ *expl_demands*: Explizite Forderungen\n",
    "+ *impl_demands*: Implizite Forderungen\n",
    "+ *all_demands*: Alle Forderungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muss ausgeführt werden, wenn das Notebook in Colab ausgeführt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!git clone https://github.com/maria-becker/Moralization/\n",
    "!pip install HanTa\n",
    "!pip install xlsxwriter\n",
    "%cd \"/content/Moralization/Annotation Analysis Tools/data_analysis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die import-Statements müssen immer ausgeführt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import label_filtering as lf\n",
    "import corpus_extraction as ce\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suchfunktionen (Einzelte Korpusdateien)\n",
    "Code für die Analyse einzelner XMI-Dateien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier bitte den Dateipfad zur hochgeladenen XMI-Datei spezifizieren.\n",
    "*Am einfachsten die Datei im Ordersystem rechtsklicken und dann -> 'Pfad kopieren'. Und unbedingt den Pfad in Anführungszeichen setzen und davor ein kleines \"r\"!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"C:\\Users\\Bruno\\Desktop\\Leserbriefe-neg-BB-neu-optimiert-RR.xmi\"\n",
    "corpus = ce.CorpusData(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der folgenden Funktion kann nach Lexemen, die als eine bestimmte Kategorie annotiert wurden, gesucht werden.\n",
    "\n",
    "Parameter:\n",
    "+ Der erste Parameter ist das Korpus. Hier einfach *corpus* stehen lassen.\n",
    "+ Der zweite Parameter ist das Lexem, das gesucht werden soll\n",
    "+ Der dritte Parameter ist die Kategorie, in der die Wortart gesucht werden soll, s.o.\n",
    "+ Der vierte Parameter gibt die Sprache des Korpus an. **ACHTUNG: Bis jetzt werden nur das Deutsche (\"ger\") und das Englische (\"en\") unterstützt. Weitere Sprachen werden folgen.**\n",
    "+ Der letzte Parameter *export* (*True* oder *False*) gibt an, ob die Daten als csv-Datei im derzeitigen Verzeichnis abgelegt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf.word_label_instances(corpus,\n",
    "\t\t\t\t\t\t\"Demokratie\",\n",
    "\t\t\t\t\t\t\"all_morals\",\n",
    "\t\t\t\t\t\tlanguage=\"en\",\n",
    "\t\t\t\t\t\texport=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mit der folgenden Funktion kann nach Wortarten, die als eine bestimmte Kategorie annotiert wurden, gesucht werden.\n",
    "Die Funktion nutzt das [Stuttgart-Tübingen-Tagset](https://homepage.ruhr-uni-bochum.de/stephen.berman/Korpuslinguistik/Tagsets-STTS.html)\n",
    "\n",
    "Parameter:\n",
    "+ Der erste Parameter ist das Korpus. Hier einfach *corpus* stehen lassen.\n",
    "+ Der zweite Parameter ist die Wortart, die gesucht werden soll\n",
    "+ Der dritte Parameter ist die Kategorie, in der das Lexem gesucht werden soll, s.o.\n",
    "+ Der vierte Parameter gibt die Sprache des Korpus an. **ACHTUNG: Bis jetzt werden nur das Deutsche (\"ger\") und das Englische (\"en\") unterstützt. Weitere Sprachen werden folgen.**\n",
    "+ Der letzte Parameter *export* (*True* oder *False*) gibt an, ob die Daten als csv-Datei im derzeitigen Verzeichnis abgelegt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf.pos_label_instances(corpus,\n",
    "\t\t\t\t\t\t\"NE\",\n",
    "\t\t\t\t\t\t\"protagonists\",\n",
    "\t\t\t\t\t\tlanguage=\"ger\",\n",
    "\t\t\t\t\t\texport=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der folgenden Funktion kann nach einer Liste von Wortarten, die als eine bestimmte Kategorie annotiert wurden, gesucht werden. Diese Suche hat daher ihre eigene Funktion, weil das [Stuttgart-Tübingen-Tagset](https://homepage.ruhr-uni-bochum.de/stephen.berman/Korpuslinguistik/Tagsets-STTS.html) oft größere Wortarten wie Pronomen weiter aufteilt.\n",
    "\n",
    "Parameter:\n",
    "+ Der erste Parameter ist das Korpus. Hier einfach *corpus* stehen lassen.\n",
    "+ Der zweite Parameter ist die Wortart, die gesucht werden soll\n",
    "+ Der dritte Parameter ist die Kategorie, in der die Wortart gesucht werden soll, s.o.\n",
    "+ Der vierte Parameter gibt die Sprache des Korpus an. **ACHTUNG: Bis jetzt werden nur das Deutsche (\"ger\") und das Englische (\"en\") unterstützt. Weitere Sprachen werden folgen.**\n",
    "+ Der letzte Parameter *export* (*True* oder *False*) gibt an, ob die Daten als csv-Datei im derzeitigen Verzeichnis abgelegt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf.poslist_label_instances(corpus,\n",
    "\t\t\t\t\t\t\t[\"NE\", \"NN\"],\n",
    "\t\t\t\t\t\t\t\"protagonists\",\n",
    "\t\t\t\t\t\t\tlanguage=\"ger\",\n",
    "\t\t\t\t\t\t\texport=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der folgenden Funktion kann nach Anzahlen von Kategorie-Vergaben gesucht werden. Zum Beispiel können alle Funktionen mit zwei Protagonisten gesucht werden.\n",
    "\n",
    "Parameter:\n",
    "+ Der erste Parameter ist das Korpus. Hier einfach *corpus* stehen lassen.\n",
    "+ Der zweite Parameter *count* ist die Anzahl, die gesucht werden soll\n",
    "+ Der dritte Parameter ist die Kategorie, die *count* Mal vergeben wurde\n",
    "+ Der letzte Parameter *export* (*True* oder *False*) gibt an, ob die Daten als csv-Datei im derzeitigen Verzeichnis abgelegt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf.count_label_instances(corpus,\n",
    "\t\t\t\t\t\t\t2,\n",
    "\t\t\t\t\t\t\t\"protagonists\",\n",
    "\t\t\t\t\t\t\texport=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der folgenden Funktion kann nach spezifischen Labeln gesucht werden werden. Zum Beispiel können alle Funktionen herausgesucht werden, in denen ein Protagonist als \"Benefizient\" markiert wurde.\n",
    "\n",
    "Parameter:\n",
    "+ Der erste Parameter ist das Korpus. Hier einfach *corpus* stehen lassen.\n",
    "+ Der zweite Parameter ist das Label, nach dem gesucht werden soll\n",
    "+ Der dritte Parameter ist die Kategorie, aus der das Label stammt\n",
    "+ Der letzte Parameter *export* (*True* oder *False*) gibt an, ob die Daten als csv-Datei im derzeitigen Verzeichnis abgelegt werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf.tag_label_instances(corpus,\n",
    "\t\t\t\t\t\t\"Benefizient:in\",\n",
    "\t\t\t\t\t\t\"protagonists\",\n",
    "\t\t\t\t\t\texport=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
